---
date: 2025-11-14 10:44:31
title: Robotic Arm Research
categories: [Robotics, Engineering]
tags: [Robotic Arm, Engineering]
math: true
---

## GraspGen

[GraspGen: A Diffusion-based Framework for 6-DOF
Grasping with On-Generator Training](https://arxiv.org/pdf/2507.13097)

這篇論文介紹了一個名為 GraspGen 的新型機器人抓取框架。這是一個基於 AI（擴散模型）的系統，用於解決 6 自由度（6-DOF）的機器人抓取問題，讓機器人能以任意角度和位置抓取物體。

這篇論文的核心貢獻是提出了一種稱為 「On-Generator Training」（基於生成器的訓練）的訓練方法，大幅提高了抓取的成功率和泛化能力。

1. 核心問題：為什麼抓取很難？

   - **泛化能力差**：過去的 AI 抓取模型雖然在模擬中表現不錯，但很難泛化到不同的機器人夾爪、不同的物體，或是在充滿雜物的真實世界場景中 。

   - **基準測試（Benchmark）成績低**： 論文指出，在一些困難的抓取基準測試（如 FetchBench）上，SOTA（最先進的）模型的成功率甚至低於 20% 。這表明現有方法遠未達到「開箱即用」的程度。

   - **模型限制**： 許多舊方法要麼需要精確的物體模型 ，要麼需要多角度掃描 （這在雜亂場景中不可行），要麼難以適應不同形狀的夾爪 。

2. GraspGen 的雙重架構
   GraspGen 框架由兩個主要部分組成：

   1. **抓取生成器 (Generator)**：

      - 這是一個 Diffusion-Transformer 架構，使用 PointTransformerV3 作為其骨幹。

      - 作用： 它的任務是「產生」大量可能的抓取姿勢。它以物體的點雲（3D 掃描）為輸入，然後像 DALL-E 生成圖片一樣，從噪聲中「去噪」並生成數百個潛在的抓取點 。

   2. **抓取評估器 (Discriminator)**：

      - 這是一個高效的分類器（一個 MLP 神經網路）。

      - 作用： 它的任務是「評分」。它會檢視生成器提供的每一個抓取姿勢，並給出一個成功率分數（例如 0 到 1 分）。最後，系統只會選擇分數最高的抓取姿勢去執行。

3. 關鍵創新：**On-Generator Training**

   - **傳統訓練的缺陷**： 傳統上，評估器（Discriminator）是使用一個「離線」（Offline）數據集來訓練的。這個數據集包含手動標記的「好抓取」和「壞抓取」。但論文作者發現，AI 生成器（Generator）實際會犯的錯誤，與離線數據集中的「壞抓取」範例分布並不相同 。

   - **GraspGen 的解決方案**： 他們設計了一種新的訓練流程 (Algorithm 1) ：

     1. 先訓練好抓取生成器（Generator）。

     2. 讓這個訓練好的生成器去產生一個全新的數據集（稱為 On-Generator Dataset）。這個新數據集裡充滿了生成器「認為」的好抓取（但其中包含許多它特有的錯誤和假陽性）。

     3. 將這個新數據集拿到模擬器中去標註，找出哪些抓取真的成功、哪些失敗了 。

     4. 只使用這個新數據集來訓練評估器（Discriminator）。

   - 效果： 經過這個流程，評估器變得「非常了解生成器會犯什麼樣的錯」，因此它能更精準地過濾掉那些「看起來很好，但實際會失敗」的假陽性抓取。實驗證明，這種方法訓練出的評估器，性能（AUC）比使用離線數據訓練的要高 。

4. 主要實驗結果
   GraspGen 在模擬和真實世界中都取得了頂尖的成果。

   - 模擬（單一物體）：

     - 在 Franka 夾爪的測試中，GraspGen 的抓取評分準確度（AUC）達到了 0.947 。
     - 相比之下，其他 SOTA 方法如 M2T2 (0.636)、DexDiffuser (0.344) 和 SE3-Diff (0.200) 遠遠落後 。這證明了 GraspGen 評估器的卓越性能。

   - 模擬（雜亂場景 - FetchBench）：

     - GraspGen 取得了 SOTA（最先進） 成果，抓取成功率比 M2T2 高出 7.8%，比 Contact-GraspNet 高出 16.9% 。

   - 真實機器人測試（Table 1）：

     - 在包含桌子、籃子、架子等複雜場景的真實測試中：

     - GraspGen 總體成功率為 81.3% 。

     - AnyGrasp (先前的方法) 成功率為 63.7% 。

     - M2T2 (先前的方法) 成功率為 52.6% 。

     - 尤其在困難的「架子」和「籃子」場景中，GraspGen 的成功率遠超對手，顯示了其強大的泛化能力。

5. 總結與限制

   - 貢獻：

     1. 提出了 GraspGen，一個結合了擴散生成器和高效評估器的 SOTA 框架 。

     2. 發明了 On-Generator Training，一種新穎的訓練方法，讓評估器能學習到生成器獨特的失敗模式 。

     3. 發布了一個包含 3 種夾爪、超過 5300 萬次抓取的新數據集 。

   - 限制：

     1. 計算成本高： 整個訓練流程需要約 3000 個 V100 GPU 小時 。

     2. 依賴分割： 性能依賴於上游的實例分割模型（如 SAM2）的準確性。

     3. 特定物體失敗： 論文提到，GraspGen 在抓取長方體（Cuboids）（如盒子）時表現不佳，這可能是因為訓練數據中缺乏足夠的盒狀物體。

- 補充方法細節：GraspGen 的訓練與推論過程

  **訓練階段 (學習如何「去噪」)目標**： 教會 AI 模型「一個好的抓取姿勢是什麼樣子」。

  1. 選取樣本： 從數據集中拿出一個「好的、成功的」抓取姿勢 $g$。

  2. 添加噪聲： 在這個好姿勢 $g$ 上隨機加入一定程度的「噪聲」 $\epsilon$，得到一個「被污染的、不完美的」姿勢 $\hat{g}$。

  3. 條件預測： 要求 AI 模型 (即 Diffusion-Transformer) 進行預測。但這個預測是有條件的 (conditional)。模型會同時看到：

     1. 物體的 3D 點雲 (Object Point Cloud)。
     2. 這個「被污染的」姿勢 $\hat{g}$。
     3. 噪聲的程度 (Diffusion Timestep $t$)。

  4. 學習： 模型的任務是預測出它在步驟 2 中加入的「噪聲」 $\epsilon$ 究竟是多少。

- 訓練的結果： 透過不斷重複這個過程，AI 模型學會了：「對於這個特定形狀的物體，如果我看到一個像 $\hat{g}$ 這樣不完美的抓取，我該如何『修正』它 (即預測出噪聲) 才能讓它變回完美的 $g$」。

  **推論/生成階段 (從噪聲中「創造」)目標**： 為一個全新的物體「憑空」生成一堆好的抓取姿勢。

  1. **給定條件**： 向模型提供新物體的 3D 點雲。

  2. **起始點**： 產生一個完全隨機的噪聲，這代表一個隨機、無意義的 6-DOF 姿勢 (可以想像成一張電視雪花圖)。

  3. **迭代去噪**： 模型開始反向執行訓練時的過程。它會看著物體的 3D 點雲，然後預測這個噪聲中「看起來最不像噪聲、最像抓取姿勢」的部分，並將其減去一點點。

  4. **重複**： 這個「去噪」過程會被迭代執行。論文中提到，他們發現只需要 10 個去噪步驟 ($T=10$) 就足夠了。

  5. **最終結果**： 經過 10 步驟後，那個「完全隨機的噪聲」就被模型一步步「雕刻」或「還原」成一個針對該物體、看起來非常合理的抓取姿勢。

簡單總結訓練時： 學習「如何把一個壞的抓取姿勢 (加了噪聲的好姿勢) 還原成一個好的姿勢」。生成時： 從一個最壞的姿勢 (純噪聲) 出發，一步步將其還原成一個好的姿勢。這整個過程都是以物體的 3D 點雲為條件，這就確保了它生成的抓取姿勢是專門為那個物體量身打造的。

## M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place

action primitives: 抓取、放置
