---
title: Paper
date: 2025-11-13 16:36:37
tags: [paper, research]
category: paper
---

## Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models

### 摘要

本文提出一種名為 Quantized Side Tuning (QST) 的訓練框架，旨在快速且記憶體效率高地微調大型語言模型（LLMs）。該方法透過兩階段處理：

1. 將模型權重量化為 4-bit，減少儲存所需的記憶體。
2. 設計一個與主模型分離的「側邊網路（side network）」，該網路僅根據主模型的隱藏層輸出進行任務預測，從而避免在主模型上進行反向傳播，進一步減少中介激活值的記憶體消耗。

此外，QST 運用低秩適配器（如 LoRA、Adapter）與無梯度下取樣模組來降低可訓練參數數量。實驗顯示，QST 能夠將總記憶體占用降低至最多 1/7，訓練速度提升 3 倍，並在準確率上保持與現有最先進方法相當的水準。

### 前言

隨著大型語言模型（LLMs）不斷增大（達數百億參數），其在微調過程中所需的記憶體與計算資源急遽上升。現有的 PEFT（參數高效率微調）雖能部分減少訓練參數，但仍需保留大量中介激活值，因此無法從根本上解決記憶體瓶頸。本文提出 QST，目的在於同時解決模型權重、優化器狀態與中介激活值三大記憶體來源問題。

### 研究目的本研究主要目的為：

- 設計一個針對量化 LLMs 的記憶體節省且快速微調方法。
- 減少三個主要記憶體負擔來源：模型權重、優化器狀態與中介激活值。
- 維持微調後模型的高效性能，並提升在多種下游任務上的表現。

### 文獻探討

- 2.1 Parameter-Efficient Finetuning：
  回顧 PEFT 方法如 LoRA、Adapters、Prompt Tuning 等，其特點在於僅微調少量參數；但這些方法仍需保留大部分中介激活值，導致記憶體需求仍偏高。

- 2.2 Memory-Efficient Training and Finetuning：
  探討如 Gradient Checkpointing、可逆網路、網路剪枝與蒸餾等降低記憶體需求技術，指出這些技術或需額外運算、或不適用於大模型；因此提出 QST 為一種可針對全模型大小皆適用的解法。

### 研究方法

- 研究設計：
  提出 QST 架構，包含 4-bit 量化與 side tuning 雙階段設計。

- 研究對象：
  使用多種主流 LLM 架構（如 OPT、LLaMA-2）進行實驗，涵蓋模型參數從 1.3B 至 70B。

- 研究工具：
  實作於 PyTorch 與 HuggingFace 平台，使用 NF4 為 4-bit 資料型態、bfloat16 為計算型態。

- 資料處理與分析：
  評估模型在 GLUE、MMLU 等標準資料集上的準確率與記憶體消耗，並以 FLOPS/token 量測訓練速度。

### 研究結果

- 記憶體消耗： QST 可比 QLoRA 降低記憶體使用量高達 2.3 倍。
- 訓練速度： 相較 QLoRA 提升 3 倍以上。
- 準確率： 在 GLUE 與 MMLU 數據集上與 QLoRA 等方法表現相當，誤差小於 1%。
- 模型擴展性： 可有效應用於 70B 參數的 LLaMA-2 模型。
- 下取樣模組比較： Adapter 為最佳方案，在效能與記憶體效率間取得平衡。
- 應用測試： 在 MT-Bench 聊天測試中，QST 甚至超越原始 LLaMA-2-70B 模型。

### 結論與建議

- 結論：
  - QST 為一項具突破性的微調方法，能在不犧牲效能的情況下，顯著降低訓練資源消耗，特別適合應用於記憶體受限的現實場景。
- 建議：
  - 未來可擴展 QST 至多模態模型。
  - 探索更多無參數下取樣方法，以進一步降低資源需求。
  - 深入研究 QST 於推論時的優化策略。

### 需要查的

- gradient checkpointing
- PEFT
- quantization
- QLoRA
- finetuning
- side network
- LLM head

## ADO-LLM: Analog Design Bayesian Optimization with In-Context Learning of Large Language Models

- BO: Bayesian Optimization

  想像一下你正在一個伸手不見五指的漆黑房間裡，你想找到房間中最深的那個「坑」（也就是最佳設計點）。

  唯一能做的，就是用一根很長的拐杖去戳地上的某個點，然後測量那個點的深度。

  - **問題**：房間太大了，你不可能把每個點都戳一遍。而且每戳一次（代表一次電路模擬）都要花費很多時間和力氣 。

  - **目標**：用最少的次數，找到那個最深的坑。

  這時，BO (貝氏優化) 就是你採用的「聰明策略」：

  1. **開始 (戳幾個點)**：你先隨便戳 5 個點，然後把它們的深度和位置記在一張紙上 。
  2. **畫出「猜想地圖」 (代理模型)**：你看著這 5 個點的數據，開始在腦中「猜想」整個房間的地形。你會想：「嗯，A 點和 B 點都很深，它們中間的 C 點可能也很深。」這張你猜想的地圖，就是 BO 中的「代理模型」(Surrogate Model) 。

  3. **決定下一步戳哪裡 (採集函數)**：這時你面臨一個抉擇：

     - **利用 (Exploitation)**：你應該在你目前找到的「最深點」附近再多戳幾下，因為真正的最深點很可能就在旁邊 。

     - **探索 (Exploration)**：或者，你應該去一個你「完全沒戳過」的遙遠角落戳一下？雖然那裡可能很淺，但也萬一那裡藏著一個更深的坑呢？

  4. **聰明的 BO**：BO 的厲害之處在於，它有一個數學公式（叫做「採集函數」），可以幫你完美地平衡這兩種衝動。它會告訴你「下一步戳哪裡」的 CP 值最高。

  5. **重複**：你戳了 BO 建議的那個新點，更新了你腦中的地圖 ，然後 BO 再給你下一個建議……如此循環，直到你找到那個最深的坑。

  BO 是一種用最少嘗試次數，去找到「黑盒子」（你不知道內部運作原理，只能靠嘗試）的最佳答案的優化方法。

  在這篇論文中：

  - 房間就是「所有可能的電路參數組合」。
  - 坑的深度就是「電路設計的好壞」(FOM) 。
  - 戳一次拐杖就是「跑一次 HSPICE 電路模擬」。
  - BO 的局限：如果房間太大（高維度問題），BO 還是會覺得很貴很慢 。
  - ADO-LLM 的幫助：這就像你旁邊多了一個「有經驗的專家」(LLM)，他雖然也看不見，但他會根據經驗跟你說：「我猜西邊角落可能不錯。」 這能讓 BO 更快地找到高價值的區域。

| 特性     | BO (貝氏優化)                                               | LLM (大型語言模型)                                                 |
| -------- | ----------------------------------------------------------- | ------------------------------------------------------------------ |
| 本質     | 一個數學優化工具                                            | 一個知識生成模型                                                   |
| 知識來源 | 零 。它從零開始，只學習「當下」這批模擬數據 。              | 龐大。它從海量的預訓練數據（網路、書籍）中學到了先驗知識 。        |
| 如何工作 | 依賴數學（採集函數）來平衡「探索」和「利用」 。             | 依賴語言、範例（In-Context Learning）和推理（Chain-of-Thought） 。 |
| 優點     | 擅長探索。能系統性地搜索整個 空間，不會被範例限制 。        | 擅長利用知識。能快速生成「可行」的設計點 ，理解電路原理 。         |
| 缺點     | 黑盒子 。它不懂「類比電路」，只看數字 。在高維度時效率低 。 | 不擅長探索。傾向於「模仿」看過的範例 ，容易卡在局部最佳解 。       |

### Abstract

這篇論文的核心是提出一個名為 ADO-LLM 的新框架，它首次將大型語言模型 (LLM) 與貝氏優化 (Bayesian Optimization, BO) 結合起來，用於自動化類比電路設計 。

- **問題背景**：類比電路設計非常依賴人類的專業知識，是提高生產效率的瓶頸 。

- **現有方法 (BO)**：貝氏優化 (BO) 是一種流行的機器學習策略，已被用於自動化類比設計 。但傳統 BO 在高維度問題上，無論是計算成本還是數據使用效率都很高。

- **ADO-LLM 的解決方案**：

  - **LLM 輔助 BO**：ADO-LLM 利用 LLM 注入領域知識的能力，快速生成可行的設計點，以彌補 BO 在數據稀少時尋找高價值設計區域的低效率 。

  - **BO 輔助 LLM**：同時，BO 迭代過程中評估的設計點，為 LLM 提供了高質量的「範例」(demonstrations)，使其能生成更高質量的設計 。

  - **互利共生**：BO 的「探索」能力（Exploration）帶來了設計的多樣性，這豐富了 LLM 的上下文理解，使其能更廣泛地搜索，並避免提出重複的建議 。

- **結論**：該框架在兩種不同的類比電路上進行了評估，證實其在設計效率和成效上都有顯著改進。

### Introduction

引言深入探討了「為什麼」需要這個新框架。

- **類比電路設計的挑戰**：

  - **設計空間巨大**：類比電路「尺寸設定」(sizing) 是一個極其複雜的任務 。
  - **多目標權衡**：設計師需要在多個競爭目標（如功率、面積、性能）之間找到微妙的平衡 。

- **現有方法的局限**：

  - **BO 的局限**：

    1. **黑盒子**：BO 缺乏特定領域的類比設計知識 。它只看最終的「品質因數」(FOM)，而不懂電晶體操作區域等模擬器提供的「過程反饋」。
    2. **多目標困難**：BO 擅長單目標優化，但在多目標權衡上表現不佳 。

  - **LLM 的局限**：
    1. **依賴範例**：LLM 的優化質量高度依賴輸入範例 (demonstrations) 的質量 。
    2. **不敢探索**：LLM 傾向於「模仿」它所看到的範例，不願意探索範例之外的新設計區域 。

- **ADO-LLM 的動機**： 本文提出的 ADO-LLM 框架 ，旨在結合兩者的優點：
  - BO 受益於 LLM 的領域知識，能更快找到好的設計區域 。
  - LLM 受益於 BO 的探索能力，能看到更多樣化、高質量的範例，從而打破模仿的限制，更廣泛地搜索 。

### Methodology

這部分解釋了 ADO-LLM 的具體運作方式，您可以對照圖 1 來理解。

該框架主要由四個組件構成：GP-BO 提議器、LLM 代理、高質量數據採樣器和 HSPICE 模擬器 。

**步驟 1：初始化 (左側 1, 2 區塊)**

1. **設定 LLM**：一開始，研究人員會向 LLM 代理提供電路定義、設計規格（例如：增益 > 60dB）和設計指令 。

2. **零樣本 (Zero-shot) 生成**：LLM 代理利用其龐大的預訓練知識，以「零樣本」的方式（即不看任何範例）生成一組初始的設計點 。

**步驟 2：優化迴圈 (右側 3 區塊)** 這是框架運作的核心。LLM 和 BO 會並行工作，提出新的設計參數。

1. GP-BO 提議器 (BO 的工作)：

   - BO 會查看所有「已收集數據」。
   - 它使用高斯過程 (GP) 模型來預測整個設計空間 。
   - 它的目標是平衡「探索」（Exploration，嘗試不確定的新區域）和「利用」（Exploitation，深入已知的高分區域）。
   - BO 會提出 4 個新的候選參數（根據實驗設定）。

2. LLM 代理 (LLM 的工作)：

   - 高質量數據採樣器：首先，採樣器會從「已收集數據」中，挑選出 FOM (品質因數) 排名前 k（例如前 5 名）的高質量範例 。
   - 情境學習 (In-context Learning)：LLM 會讀取這些「少樣本範例」(Few-shot Demonstrations) 。
   - 思考鏈 (Chain-of-Thought)：LLM (使用 ChatGPT-3.5 Turbo ) 會被引導進行多步推理 ，例如：a. 解釋電路定義 → b. 權衡設計規格 → c. 參考少樣本範例 → d. 遵循設計原則（例如確保電晶體在特定區域工作）。
   - LLM 會提出 1 個新的候選參數 。

3. 模擬與迭代：
   - 來自 BO (4 個) 和 LLM (1 個) 的所有新參數，都會被送入 HSPICE 模擬器進行評估 。
   - 模擬結果（包含 FOM 和電晶體狀態等）會作為「新數據」被添加回「已收集數據」中 。
   - 重複步驟 2，迴圈繼續。

### Experiments and Results

研究人員在兩個電路上測試了 ADO-LLM，並與單獨的「GP-BO」（隨機初始化）和「LLM 代理」進行了比較 。

**實驗 1：兩級差動放大器 (Table 3)**

- 結果：ADO-LLM 是唯一滿足所有 5 項設計規格（0 個未達標）的方法 。
- 效率：ADO-LLM 達到了最高的 FOM (3.52) 。相比之下，GP-BO 即使多花 4 倍的模擬次數 (80 次迭代)，FOM 也只有 2.10，且仍有 1 個規格未達標 。
- 結論：這證明了 ADO-LLM 在類比電路設計上的數據效率 (data efficiency) 。

**實驗 2：遲滯比較器 (Table 5)**

- 結果：結果一致。ADO-LLM 再次成為唯一滿足所有規格的方法（0 個未達標），並取得了最高的 FOM (0.90) 。
- 結論：GP-BO 和 LLM 代理單獨使用時，雖然可能在某些指標上表現出色，但無法在有限的模擬預算內平衡所有指標 。

**消融研究 (Ablation Studies)**

- **LLM 零樣本初始化的重要性 (Table 6)**：

  - 研究顯示，使用 LLM 提供的初始點（GP-BO with LLM's init）比使用隨機初始點（GP-BO with random init）能獲得更好的 FOM 。
  - 這證實了 LLM 的先驗知識確實能為優化提供一個更好的起點 。

- **高質量範例的重要性 (Table 7)**：

  - 研究比較了三種 LLM 代理：a. 不看範例 (w/o ICL)、b. 看隨機 5 個範例 (Rand 5)、c. 看 Top 5 範例。
  - 結果顯示，使用「Top 5」高質量範例的 LLM 代理，在 FOM 和滿足規格數量上均表現最佳 。
  - 有趣的是，如果給 LLM 看「隨機」範例，在比較器電路上甚至比不看範例（零樣本）的表現更差 ，這證明了範例的「質量」至關重要。

### Limitations and Future Work

儘管 ADO-LLM 表現出色，但仍有其局限性：

1. 依賴外部 LLM API：目前依賴 ChatGPT 這種閉源 API，成本高且缺乏透明度 。且這些通用 LLM 並非專為電路設計定製 。

   - 未來：可以開發針對 EDA 任務的領域適應 LLM ，或使用 RAG 技術來整合更精確的領域知識 。

2. BO 的可擴展性：高斯過程 (GP) 在面對更複雜、設計空間更龐大的電路時，可能難以擴展 。
   - 未來：可以實施分層優化策略，模仿真實人類專家的做法，每次只優化一部分參數 。

### 能問的問題

1. 只用其中一種方法（例如只用 LLM）來做電路設計，它最大的問題會是什麼？
2. 他的 LLM 是用什麼模型？為什麼選這個？
3. 我可以理解成 BO 和 LLM 的合作方式是把他們的輸出放到一個共享的資料庫?
4. FOM 是什麼
5. BO 是甚麼
6. 為什麼 Zero-Shot Initialization
